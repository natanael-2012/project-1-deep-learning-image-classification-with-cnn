{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/natanael-2012/project-1-deep-learning-image-classification-with-cnn/blob/main/site/en/tutorials/images/transfer_learning_with_hub%2C%20just%20useful%20parts.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_tvPdyfA-BL"
      },
      "source": [
        "##### Copyright 2018 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "0O_LFhwSBCjm"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWUmcKKjtwXL"
      },
      "source": [
        "# Transfer learning with TensorFlow Hub\n",
        "\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/images/transfer_learning_with_hub\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/images/transfer_learning_with_hub.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/transfer_learning_with_hub.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View on GitHub</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/tutorials/images/transfer_learning_with_hub.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\"><img src=\"https://www.tensorflow.org/images/hub_logo_32px.png\" />See TF Hub model</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crU-iluJIEzw"
      },
      "source": [
        "[TensorFlow Hub](https://tfhub.dev/) is a repository of pre-trained TensorFlow models.\n",
        "\n",
        "This tutorial demonstrates how to:\n",
        "\n",
        "1. Use models from TensorFlow Hub with `tf.keras`.\n",
        "1. Use an image classification model from TensorFlow Hub.\n",
        "1. Do simple transfer learning to fine-tune a model for your own image classes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKFUvuEho9Th"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "OGNpmn43C0O6"
      },
      "outputs": [],
      "source": [
        "# !pip install --upgrade tensorflow tensorflow-hub\n",
        "# !pip install --upgrade tensorflow\n",
        "# !pip install --upgrade tf-keras\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "import PIL.Image as Image\n",
        "import matplotlib.pylab as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "import tf_keras\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "import datetime\n",
        "\n",
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4YuF5HvpM1W"
      },
      "source": [
        "## An ImageNet classifier\n",
        "\n",
        "You'll start by using a classifier model pre-trained on the [ImageNet](https://en.wikipedia.org/wiki/ImageNet) benchmark datasetâ€”no initial training required!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amfzqn1Oo7Om"
      },
      "source": [
        "## Simple transfer learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-nIpVJ94xrw"
      },
      "source": [
        "But what if you want to create a custom classifier using your own dataset that has classes that aren't included in the original ImageNet dataset (that the pre-trained model was trained on)?\n",
        "\n",
        "To do that, you can:\n",
        "\n",
        "1. Select a pre-trained model from TensorFlow Hub; and\n",
        "2. Retrain the top (last) layer to recognize the classes from your custom dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z93vvAdGxDMD"
      },
      "source": [
        "### Dataset\n",
        "\n",
        "In this example, you will use the Animals-10 dataset:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Download dataset directly from Kaggle (if running on colab)\n",
        "if os.path.exists('/root/.cache/kagglehub/datasets/alessiocorrado99/animals10/versions/2'):\n",
        "  path = Path('/root/.cache/kagglehub/datasets/alessiocorrado99/animals10/versions/2')\n",
        "  print(\"Dataset already downloaded\")\n",
        "else:\n",
        "  path = kagglehub.dataset_download(\"alessiocorrado99/animals10\")\n",
        "\n",
        "#   path = kagglehub.dataset_download(\"alessiocorrado99/animals10\")\n",
        "\n",
        "# Define the raw images path\n",
        "raw_img_path = os.path.join(path, 'raw-img')  # Adjust based on the downloaded structure\n",
        "\n",
        "# Verify dataset structure\n",
        "if os.path.exists(raw_img_path):\n",
        "    print(\"Dataset downloaded and extracted successfully!\")\n",
        "    print(\"Path to dataset files:\", path)\n",
        "    print(\"Path to raw images:\", raw_img_path)\n",
        "    print(\"Categories:\", os.listdir(raw_img_path))  # List categories in the raw images folder\n",
        "else:\n",
        "    print(\"Error: raw-img folder not found. Please verify the dataset structure.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8cFbgUX5hkA",
        "outputId": "c7f62371-a58a-41d4-ed3b-d1da6c5e9747"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset already downloaded\n",
            "Dataset downloaded and extracted successfully!\n",
            "Path to dataset files: /root/.cache/kagglehub/datasets/alessiocorrado99/animals10/versions/2\n",
            "Path to raw images: /root/.cache/kagglehub/datasets/alessiocorrado99/animals10/versions/2/raw-img\n",
            "Categories: ['scoiattolo', 'ragno', 'pecora', 'gallina', 'farfalla', 'cavallo', 'mucca', 'gatto', 'cane', 'elefante']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Parameters for preprocessing\n",
        "img_size = (224, 224)  # Resize all images to 128x128 pixels\n",
        "batch_size = 32  # Load data in batches of 32\n",
        "img_height = 224\n",
        "img_width = 224 # copied, in case they reuse it in the og tutorial\n",
        "\n",
        "# Data preprocessing and augmentation\n",
        "# datagen = ImageDataGenerator(\n",
        "#     rescale=1./255,  # Normalize pixel values to [0, 1]\n",
        "#     validation_split=0.2  # Use 20% of the data for validation\n",
        "# )\n",
        "\n",
        "# Training data generator\n",
        "print(\"Creating training data generator...\")\n",
        "train_data = tf.keras.utils.image_dataset_from_directory(\n",
        "    str(raw_img_path),  # Path to raw images\n",
        "    image_size=img_size,  # Resize images to 128x128\n",
        "    batch_size=batch_size,  # Batch size for training\n",
        "    seed = 42,\n",
        "    # class_mode='categorical',  # Multi-class classification\n",
        "    subset='training',  # Training data\n",
        "    validation_split=0.2  # Use 20% of the data for validation\n",
        ")\n",
        "\n",
        "# Validation data generator\n",
        "print(\"Creating validation data generator...\")\n",
        "val_data = tf.keras.utils.image_dataset_from_directory(\n",
        "    str(raw_img_path),  # Path to raw images\n",
        "    image_size=img_size,  # Resize images to 128x128\n",
        "    batch_size=batch_size,  # Batch size for validation\n",
        "    # class_mode='categorical',  # Multi-class classification\n",
        "    seed = 42,\n",
        "    subset='validation',  # Validation data\n",
        "    validation_split = 0.2  # Use 20% of the data for validation\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBTQJH9_5r0x",
        "outputId": "11541531-1029-4d6d-b093-f932753ce104"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating training data generator...\n",
            "Found 26179 files belonging to 10 classes.\n",
            "Using 20944 files for training.\n",
            "Creating validation data generator...\n",
            "Found 26179 files belonging to 10 classes.\n",
            "Using 5235 files for validation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCrSRlomEIZ4"
      },
      "source": [
        "The Animals-10 dataset has 10 classes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "AFgDHs6VEFRD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73ec11f4-7795-4211-8e8a-3a39ab768fd0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['cane' 'cavallo' 'elefante' 'farfalla' 'gallina' 'gatto' 'mucca' 'pecora'\n",
            " 'ragno' 'scoiattolo']\n"
          ]
        }
      ],
      "source": [
        "class_names = np.array(train_data.class_names)\n",
        "print(class_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0Btd0V3C8h4"
      },
      "source": [
        "Second, because TensorFlow Hub's convention for image models is to expect float inputs in the `[0, 1]` range, use the `tf.keras.layers.Rescaling` preprocessing layer to achieve this."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rs6gfO-ApTQW"
      },
      "source": [
        "Note: You could also include the `tf.keras.layers.Rescaling` layer inside the model. Refer to the [Working with preprocessing layers](https://www.tensorflow.org/guide/keras/preprocessing_layers) guide for a discussion of the tradeoffs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "8NzDDWEMCL20"
      },
      "outputs": [],
      "source": [
        "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
        "train_ds = train_data.map(lambda x, y: (normalization_layer(x), y)) # Where xâ€”images, yâ€”labels.\n",
        "val_ds = val_data.map(lambda x, y: (normalization_layer(x), y)) # Where xâ€”images, yâ€”labels."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IW-BUJ-NC7y-"
      },
      "source": [
        "Third, finish the input pipeline by using buffered prefetching with `Dataset.prefetch`, so you can yield the data from disk without I/O blocking issues.\n",
        "\n",
        "These are some of the most important `tf.data` methods you should use when loading data. Interested readers can learn more about them, as well as how to cache data to disk and other techniques, in the [Better performance with the tf.data API](https://www.tensorflow.org/guide/data_performance#prefetching) guide."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ZmJMKFw7C4ki"
      },
      "outputs": [],
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "m0JyiEZ0imgf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "248a78a1-4bb2-44f4-f3fa-e3d16db4242c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32, 224, 224, 3)\n",
            "(32,)\n"
          ]
        }
      ],
      "source": [
        "for image_batch, labels_batch in train_ds:\n",
        "  print(image_batch.shape)\n",
        "  print(labels_batch.shape)\n",
        "  break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzV457OXreQP"
      },
      "source": [
        "### Download the headless model\n",
        "\n",
        "TensorFlow Hub also distributes models without the top classification layer. These can be used to easily perform transfer learning.\n",
        "\n",
        "Select a <a href=\"https://arxiv.org/abs/1801.04381\" class=\"external\">MobileNetV2</a> pre-trained model <a href=\"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\" class=\"external\">from TensorFlow Hub</a>. Any <a href=\"https://tfhub.dev/s?module-type=image-feature-vector&q=tf2\" class=\"external\">compatible image feature vector model</a> from TensorFlow Hub will work here, including the examples from the drop-down menu."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "4bw8Jf94DSnP"
      },
      "outputs": [],
      "source": [
        "mobilenet_v2 = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\"\n",
        "inception_v3 = \"https://tfhub.dev/google/tf2-preview/inception_v3/feature_vector/4\"\n",
        "\n",
        "feature_extractor_model = mobilenet_v2 #@param [\"mobilenet_v2\", \"inception_v3\"] {type:\"raw\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgwmHugQF-PD"
      },
      "source": [
        "Create the feature extractor by wrapping the pre-trained model as a Keras layer with [`hub.KerasLayer`](https://www.tensorflow.org/hub/api_docs/python/hub/KerasLayer). Use the `trainable=False` argument to freeze the variables, so that the training only modifies the new classifier layer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "5wB030nezBwI"
      },
      "outputs": [],
      "source": [
        "feature_extractor_layer = hub.KerasLayer(\n",
        "    feature_extractor_model,\n",
        "    input_shape=(224, 224, 3),\n",
        "    trainable=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QzVdu4ZhcDE"
      },
      "source": [
        "The feature extractor returns a 1280-long vector for each image (the image batch size remains at 32 in this example):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Of7i-35F09ls",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba4bc195-36fd-4868-e3bf-00fe3a364d6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32, 1280)\n"
          ]
        }
      ],
      "source": [
        "feature_batch = feature_extractor_layer(image_batch)\n",
        "print(feature_batch.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPVeouTksO9q"
      },
      "source": [
        "### Attach a classification head\n",
        "\n",
        "To complete the model, wrap the feature extractor layer in a `tf.keras.Sequential` model and add a fully-connected layer for classification:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "vQq_kCWzlqSu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e080fb3-ca9c-420e-977a-8cca5892d297"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " keras_layer_1 (KerasLayer)  (None, 1280)              2257984   \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                12810     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2270794 (8.66 MB)\n",
            "Trainable params: 12810 (50.04 KB)\n",
            "Non-trainable params: 2257984 (8.61 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "num_classes = len(class_names)\n",
        "\n",
        "model = tf_keras.Sequential([\n",
        "  feature_extractor_layer,\n",
        "  tf_keras.layers.Dense(num_classes)\n",
        "])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "IyhX4VCFmzVS"
      },
      "outputs": [],
      "source": [
        "predictions = model(image_batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "FQdUaTkzm3jQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccefebe7-d4f1-4d68-f36b-db2b95467158"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([32, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "predictions.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHbXQqIquFxQ"
      },
      "source": [
        "### Train the model\n",
        "\n",
        "Use `Model.compile` to configure the training process and add a `tf.keras.callbacks.TensorBoard` callback to create and store logs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "4xRx8Rjzm67O"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "  optimizer='adam',\n",
        "  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "  metrics=['acc'])\n",
        "\n",
        "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf_keras.callbacks.TensorBoard(\n",
        "    log_dir=log_dir,\n",
        "    histogram_freq=1) # Enable histogram computation for every epoch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58-BLV7dupJA"
      },
      "source": [
        "Now use the `Model.fit` method to train the model.\n",
        "\n",
        "To keep this example short, you'll be training for just 10 epochs. To visualize the training progress in TensorBoard later, create and store logs an a [TensorBoard callback](https://www.tensorflow.org/tensorboard/get_started#using_tensorboard_with_keras_modelfit)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JI0yAKd-nARd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "094bd4ce-06d7-4161-8086-60f6e4e4459f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "462/655 [====================>.........] - ETA: 4:17 - loss: 0.2668 - acc: 0.9296"
          ]
        }
      ],
      "source": [
        "# AquÃ­ tumbÃ³ porque uso todo el ram\n",
        "\n",
        "NUM_EPOCHS = 10\n",
        "\n",
        "history = model.fit(train_ds,\n",
        "                    validation_data=val_ds,\n",
        "                    epochs=NUM_EPOCHS,\n",
        "                    callbacks=tensorboard_callback)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tiDbmiAK_h03"
      },
      "source": [
        "Start the TensorBoard to view how the metrics change with each epoch and to track other scalar values:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-yVJar0MiT2t"
      },
      "outputs": [],
      "source": [
        "%tensorboard --logdir logs/fit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36a9d7cab8c8"
      },
      "source": [
        "<!-- <img class=\"tfo-display-only-on-site\" src=\"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/images/tensorboard_transfer_learning_with_hub.png?raw=1\"/> -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kb__ZN8uFn-D"
      },
      "source": [
        "### Check the predictions\n",
        "\n",
        "Obtain the ordered list of class names from the model predictions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JGbEf5l1I4jz"
      },
      "outputs": [],
      "source": [
        "predicted_batch = model.predict(image_batch)\n",
        "predicted_id = tf.math.argmax(predicted_batch, axis=-1)\n",
        "predicted_label_batch = class_names[predicted_id]\n",
        "print(predicted_label_batch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkGbZxl9GZs-"
      },
      "source": [
        "Plot the model predictions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hW3Ic_ZlwtrZ"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,9))\n",
        "plt.subplots_adjust(hspace=0.5)\n",
        "\n",
        "for n in range(30):\n",
        "  plt.subplot(6,5,n+1)\n",
        "  plt.imshow(image_batch[n])\n",
        "  plt.title(predicted_label_batch[n].title())\n",
        "  plt.axis('off')\n",
        "_ = plt.suptitle(\"Model predictions\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRcJnAABr22x"
      },
      "source": [
        "## Export and reload your model\n",
        "\n",
        "Now that you've trained the model, export it as a SavedModel for reusing it later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PLcqg-RmsLno"
      },
      "outputs": [],
      "source": [
        "t = time.time()\n",
        "\n",
        "export_path = \"/tmp/saved_models/{}\".format(int(t))\n",
        "model.save(export_path)\n",
        "\n",
        "export_path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhQ9liIUsPsi"
      },
      "source": [
        "Confirm that you can reload the SavedModel and that the model is able to output the same results:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7nI5fvkAQvbS"
      },
      "outputs": [],
      "source": [
        "reloaded = tf.keras.models.load_model(export_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dnZO14taYPH6"
      },
      "outputs": [],
      "source": [
        "result_batch = model.predict(image_batch)\n",
        "reloaded_result_batch = reloaded.predict(image_batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wtjsIPjQnPyM"
      },
      "outputs": [],
      "source": [
        "abs(reloaded_result_batch - result_batch).max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jor83-LqI8xW"
      },
      "outputs": [],
      "source": [
        "reloaded_predicted_id = tf.math.argmax(reloaded_result_batch, axis=-1)\n",
        "reloaded_predicted_label_batch = class_names[reloaded_predicted_id]\n",
        "print(reloaded_predicted_label_batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RkQIBksVkxPO"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,9))\n",
        "plt.subplots_adjust(hspace=0.5)\n",
        "for n in range(30):\n",
        "  plt.subplot(6,5,n+1)\n",
        "  plt.imshow(image_batch[n])\n",
        "  plt.title(reloaded_predicted_label_batch[n].title())\n",
        "  plt.axis('off')\n",
        "_ = plt.suptitle(\"Model predictions\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSBRrW-MqBbk"
      },
      "source": [
        "## Next steps\n",
        "\n",
        "You can use the SavedModel to load for inference or convert it to a [TensorFlow Lite](https://www.tensorflow.org/lite/models/convert/)  model (for on-device machine learning) or a [TensorFlow.js](https://www.tensorflow.org/js/tutorials#convert_pretrained_models_to_tensorflowjs) model (for machine learning in JavaScript).\n",
        "\n",
        "Discover [more tutorials](https://www.tensorflow.org/hub/tutorials) to learn how to use pre-trained models from TensorFlow Hub on image, text, audio, and video tasks."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "W_tvPdyfA-BL"
      ],
      "name": "transfer_learning_with_hub.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}