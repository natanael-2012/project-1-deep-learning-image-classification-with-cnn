{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "id": "n6QHvU2dfpFz",
    "papermill": {
     "duration": 0.009603,
     "end_time": "2022-10-10T07:48:00.787323",
     "exception": false,
     "start_time": "2022-10-10T07:48:00.77772",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h1 style=\"font-family:verdana;\"> <center>üêàAnimals Image Classification using Deep Convolutional Neural Networks and Transfer Learning</center> </h1>\n",
    "<p><center style=\"color:#159364; font-family:cursive; font-size:20px;\">Thanks for visiting my notebook </center></p>\n",
    "\n",
    "***\n",
    "\n",
    "<center><img src='https://media3.giphy.com/media/4wLJ8aC0V68x2/giphy.gif?cid=ecf05e47w3cf1ag7f051p0k24qb4fuliox8xb9jegtrrg5dd&rid=giphy.gif&ct=s' height=150px width=600px></center>\n",
    "\n",
    "# üëãThanks for Visting my Notebook\n",
    "<div class=\"alert alert-block alert-info\" style=\"font-size:20px; font-family:verdana;\">\n",
    "    üìå Feel free to fork or edit the notebook for your own convenience. If you liked the notebook, consider upvoting. It helps other people discover the notebook as well. Your support inspires me to produce more of these kernel.üòä\n",
    "</div>\n",
    "\n",
    "# üî¨Overview \n",
    "\n",
    "<div style=\"background-color:#d4f1f4; padding: 20px;\">\n",
    "<p style=\"font-size:20px; font-family:verdana; line-height: 1.7em\">Animal image classification is a complex task that involves using artificial intelligence (AI) algorithms to identify and categorize animals based on their visual characteristics. This technology has numerous applications, including wildlife conservation, veterinary medicine, and even agriculture. With the advent of deep learning and computer vision technologies, it is now possible to develop highly accurate and efficient animal image classification systems that can analyze millions of images in real-time.</p>\n",
    "\n",
    "<p style=\"font-size:20px; font-family:verdana; line-height: 1.7em\">One of the primary challenges in animal image classification is dealing with the vast amount of visual data that is available. This data can be highly diverse, ranging from low-quality camera trap images to high-resolution photos captured by professional photographers. Additionally, the appearance of animals can vary significantly depending on factors such as age, sex, and location. To overcome these challenges, researchers often rely on deep learning models that can learn from large datasets and generalize well to new images.</p>\n",
    "\n",
    "<p style=\"font-size:20px; font-family:verdana; line-height: 1.7em\">Another important consideration in animal image classification is the ethical implications of this technology. While AI-powered wildlife monitoring systems have the potential to revolutionize conservation efforts, they also raise concerns about privacy, data security, and animal welfare. It is crucial for researchers and developers to prioritize ethical considerations and collaborate with stakeholders such as conservationists, animal rights groups, and indigenous communities to ensure that these systems are used responsibly and for the greater good.</p>\n",
    "</div>\n",
    "\n",
    "# ‚ùóAuthor's Note:\n",
    "<div style=\"background-color:#d4f1f4; padding: 20px;\">\n",
    "<p style=\"font-size:20px; font-family:verdana; line-height: 1.7em\">Make sure to run the cells from top to bottom with a GPU accelerator. There are some linux commands present in some cells so this is important to take into account. Also, any suggestions, comments and recommendations to improve the notebook will be highly appreciated. Cheers!</p>\n",
    "</div>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<center><img src='https://media2.giphy.com/media/iqoMlTNmQtBOHha57N/giphy.gif?cid=ecf05e47w3cf1ag7f051p0k24qb4fuliox8xb9jegtrrg5dd&rid=giphy.gif&ct=s' height=200px width=600px></center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "id": "kQELj5Dwf3on",
    "papermill": {
     "duration": 0.007933,
     "end_time": "2022-10-10T07:48:00.803524",
     "exception": false,
     "start_time": "2022-10-10T07:48:00.795591",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# üèóÔ∏èImport Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2023-04-08T09:31:18.67232Z",
     "iopub.status.busy": "2023-04-08T09:31:18.671583Z",
     "iopub.status.idle": "2023-04-08T09:31:28.098652Z",
     "shell.execute_reply": "2023-04-08T09:31:28.097556Z",
     "shell.execute_reply.started": "2023-04-08T09:31:18.672276Z"
    },
    "id": "lEzJXgjDf5y8",
    "papermill": {
     "duration": 6.140885,
     "end_time": "2022-10-10T07:48:06.952626",
     "exception": false,
     "start_time": "2022-10-10T07:48:00.811741",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Import Data Science Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import itertools\n",
    "import random\n",
    "\n",
    "# Import visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import cv2\n",
    "import seaborn as sns\n",
    "\n",
    "# Tensorflow Libraries\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers,models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import Callback, EarlyStopping,ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras import Model\n",
    "# from tensorflow.keras.layers.experimental import preprocessing\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# System libraries\n",
    "from pathlib import Path\n",
    "import os.path\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "sns.set_style('darkgrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2023-04-08T09:31:28.101338Z",
     "iopub.status.busy": "2023-04-08T09:31:28.100611Z",
     "iopub.status.idle": "2023-04-08T09:31:30.762832Z",
     "shell.execute_reply": "2023-04-08T09:31:30.761696Z",
     "shell.execute_reply.started": "2023-04-08T09:31:28.101306Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Seed Everything to reproduce results for future use cases\n",
    "def seed_everything(seed=42):\n",
    "    # Seed value for TensorFlow\n",
    "    tf.random.set_seed(seed)\n",
    "    \n",
    "    # Seed value for NumPy\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Seed value for Python's random library\n",
    "    random.seed(seed)\n",
    "    \n",
    "    # Force TensorFlow to use single thread\n",
    "    # Multiple threads are a potential source of non-reproducible results.\n",
    "    session_conf = tf.compat.v1.ConfigProto(\n",
    "        intra_op_parallelism_threads=1,\n",
    "        inter_op_parallelism_threads=1\n",
    "    )\n",
    "\n",
    "    # Make sure that TensorFlow uses a deterministic operation wherever possible\n",
    "    tf.compat.v1.set_random_seed(seed)\n",
    "\n",
    "    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "    tf.compat.v1.keras.backend.set_session(sess)\n",
    "\n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "id": "D_SnZPRah_9D",
    "papermill": {
     "duration": 0.008898,
     "end_time": "2022-10-10T07:48:06.971563",
     "exception": false,
     "start_time": "2022-10-10T07:48:06.962665",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ü§ôCreate helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "editable": false,
    "execution": {
     "iopub.execute_input": "2023-04-08T09:31:30.764833Z",
     "iopub.status.busy": "2023-04-08T09:31:30.764427Z",
     "iopub.status.idle": "2023-04-08T09:31:31.791264Z",
     "shell.execute_reply": "2023-04-08T09:31:31.789889Z",
     "shell.execute_reply.started": "2023-04-08T09:31:30.764781Z"
    },
    "id": "F8ReVC2MiBRZ",
    "outputId": "c53e6082-d883-478d-d42f-887eb8399678",
    "papermill": {
     "duration": 1.656066,
     "end_time": "2022-10-10T07:48:08.635569",
     "exception": false,
     "start_time": "2022-10-10T07:48:06.979503",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
    "\n",
    "# Import series of helper functions for our notebook\n",
    "from helper_functions import create_tensorboard_callback, plot_loss_curves, unzip_data, compare_historys, walk_through_dir, pred_and_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "id": "Hb_XPhOwiCNY",
    "papermill": {
     "duration": 0.008226,
     "end_time": "2022-10-10T07:48:08.652407",
     "exception": false,
     "start_time": "2022-10-10T07:48:08.644181",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# üì•Load and Transform Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2023-04-08T09:31:31.795339Z",
     "iopub.status.busy": "2023-04-08T09:31:31.794873Z",
     "iopub.status.idle": "2023-04-08T09:31:31.801594Z",
     "shell.execute_reply": "2023-04-08T09:31:31.800315Z",
     "shell.execute_reply.started": "2023-04-08T09:31:31.795286Z"
    },
    "id": "8nD56d7Xxmc3",
    "papermill": {
     "duration": 0.016856,
     "end_time": "2022-10-10T07:48:08.678624",
     "exception": false,
     "start_time": "2022-10-10T07:48:08.661768",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "TARGET_SIZE = (224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "try:\n",
    "  ran == True\n",
    "\n",
    "except:\n",
    "  path2 = kagglehub.dataset_download(\"alessiocorrado99/animals10\")\n",
    "\n",
    "  print(\"Path to dataset files:\", path2)\n",
    "  \n",
    "  ran = True\n",
    "else:\n",
    "  print(path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2023-04-08T09:31:31.803883Z",
     "iopub.status.busy": "2023-04-08T09:31:31.803403Z",
     "iopub.status.idle": "2023-04-08T09:31:49.583863Z",
     "shell.execute_reply": "2023-04-08T09:31:49.582591Z",
     "shell.execute_reply.started": "2023-04-08T09:31:31.803847Z"
    },
    "id": "5kXkjadNxsNI",
    "outputId": "478c212a-b21e-4e08-e472-9b101759173e",
    "papermill": {
     "duration": 0.225201,
     "end_time": "2022-10-10T07:48:08.912055",
     "exception": false,
     "start_time": "2022-10-10T07:48:08.686854",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Walk through each directory\n",
    "dataset = path2+ \"/raw-img\"\n",
    "print(path2)\n",
    "walk_through_dir(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "id": "MLAnhGlf1hmo",
    "papermill": {
     "duration": 0.008438,
     "end_time": "2022-10-10T07:48:08.929209",
     "exception": false,
     "start_time": "2022-10-10T07:48:08.920771",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# üìÖPlacing data into a Dataframe\n",
    "<div style=\"background-color:#f2f2f2; padding: 20px;\">\n",
    "<p style=\"font-size:20px; font-family:verdana; line-height: 1.7em\">The first column <b>filepaths</b> contains the file path location of each individual images. The second column <b>labels</b>, on the other hand, contains the class label of the corresponding image from the file path</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2023-04-08T09:31:49.585997Z",
     "iopub.status.busy": "2023-04-08T09:31:49.585611Z",
     "iopub.status.idle": "2023-04-08T09:31:53.868123Z",
     "shell.execute_reply": "2023-04-08T09:31:53.867003Z",
     "shell.execute_reply.started": "2023-04-08T09:31:49.585958Z"
    },
    "id": "s14XOEp01m_s",
    "papermill": {
     "duration": 0.122033,
     "end_time": "2022-10-10T07:48:09.059708",
     "exception": false,
     "start_time": "2022-10-10T07:48:08.937675",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def convert_path_to_df(dataset):\n",
    "    image_dir = Path(dataset)\n",
    "\n",
    "    # Get filepaths and labels\n",
    "    filepaths = list(image_dir.glob(r'**/*.JPG')) + list(image_dir.glob(r'**/*.jpg')) + list(image_dir.glob(r'**/*.jpeg')) + list(image_dir.glob(r'**/*.PNG'))\n",
    "\n",
    "    labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], filepaths))\n",
    "\n",
    "    filepaths = pd.Series(filepaths, name='Filepath').astype(str)\n",
    "    labels = pd.Series(labels, name='Label')\n",
    "\n",
    "    # Concatenate filepaths and labels\n",
    "    image_df = pd.concat([filepaths, labels], axis=1)\n",
    "    return image_df\n",
    "\n",
    "image_df = convert_path_to_df(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2023-04-08T09:31:53.870055Z",
     "iopub.status.busy": "2023-04-08T09:31:53.869681Z",
     "iopub.status.idle": "2023-04-08T09:32:05.74075Z",
     "shell.execute_reply": "2023-04-08T09:32:05.73969Z",
     "shell.execute_reply.started": "2023-04-08T09:31:53.870015Z"
    },
    "papermill": {
     "duration": 0.018247,
     "end_time": "2022-10-10T07:48:09.086599",
     "exception": false,
     "start_time": "2022-10-10T07:48:09.068352",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Check for corrupted images within the dataset\n",
    "import PIL\n",
    "from pathlib import Path\n",
    "from PIL import UnidentifiedImageError\n",
    "\n",
    "path = Path(dataset).rglob(\"*.jpg\")\n",
    "for img_p in path:\n",
    "    try:\n",
    "        img = PIL.Image.open(img_p)\n",
    "    except PIL.UnidentifiedImageError:\n",
    "            print(img_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2023-04-08T09:32:05.742624Z",
     "iopub.status.busy": "2023-04-08T09:32:05.742217Z",
     "iopub.status.idle": "2023-04-08T09:32:06.106121Z",
     "shell.execute_reply": "2023-04-08T09:32:06.105085Z",
     "shell.execute_reply.started": "2023-04-08T09:32:05.742583Z"
    },
    "id": "d3-uoP4n1oqK",
    "outputId": "4af0c4a5-c87d-42eb-aa1b-fe89f1fe8876",
    "papermill": {
     "duration": 0.031437,
     "end_time": "2022-10-10T07:48:09.12635",
     "exception": false,
     "start_time": "2022-10-10T07:48:09.094913",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Get the value counts for each label\n",
    "label_counts = image_df['Label'].value_counts()\n",
    "\n",
    "# Create the figure and axes\n",
    "fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(20, 6))\n",
    "\n",
    "# Plot the bar chart\n",
    "sns.barplot(x=label_counts.index, y=label_counts.values, alpha=0.8, palette='pastel', ax=axes)\n",
    "axes.set_title('Distribution of Labels in Image Dataset', fontsize=16)\n",
    "axes.set_xlabel('Label', fontsize=14)\n",
    "axes.set_ylabel('Count', fontsize=14)\n",
    "axes.set_xticklabels(label_counts.index, rotation=45)\n",
    "\n",
    "# Add a super-title to the figure\n",
    "fig.suptitle('Image Dataset Label Distribution', fontsize=20)\n",
    "\n",
    "# Adjust the spacing between the plots and the title\n",
    "fig.subplots_adjust(top=0.85)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "id": "agb1QMDO1pps",
    "papermill": {
     "duration": 0.008541,
     "end_time": "2022-10-10T07:48:09.143972",
     "exception": false,
     "start_time": "2022-10-10T07:48:09.135431",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# üî≠Visualizing images from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2023-04-08T09:32:06.107698Z",
     "iopub.status.busy": "2023-04-08T09:32:06.107328Z",
     "iopub.status.idle": "2023-04-08T09:32:07.487254Z",
     "shell.execute_reply": "2023-04-08T09:32:07.486301Z",
     "shell.execute_reply.started": "2023-04-08T09:32:06.107649Z"
    },
    "id": "m4WJVJ7j1rU9",
    "outputId": "777f0f9a-e46c-4475-ca6a-97a4e6fb89a3",
    "papermill": {
     "duration": 1.190226,
     "end_time": "2022-10-10T07:48:10.343152",
     "exception": false,
     "start_time": "2022-10-10T07:48:09.152926",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Display 16 picture of the dataset with their labels\n",
    "random_index = np.random.randint(0, len(image_df), 16)\n",
    "fig, axes = plt.subplots(nrows=4, ncols=4, figsize=(10, 10),\n",
    "                        subplot_kw={'xticks': [], 'yticks': []})\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(plt.imread(image_df.Filepath[random_index[i]]))\n",
    "    ax.set_title(image_df.Label[random_index[i]])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "papermill": {
     "duration": 0.019658,
     "end_time": "2022-10-10T07:48:10.381267",
     "exception": false,
     "start_time": "2022-10-10T07:48:10.361609",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# üßÆComputing Error Rate Analysis\n",
    "\n",
    "<div style=\"background-color:#f2f2f2; padding: 20px;\">\n",
    "<p style=\"font-size:20px; font-family:verdana; line-height: 1.7em\">The code below is used for error level analysis (ELA) of images in the context of a animals image classification task.</p>\n",
    "\n",
    "<p style=\"font-size:20px; font-family:verdana; line-height: 1.7em\">The compute_ela_cv() function takes an image path and a quality parameter, compresses the image using JPEG compression at the given quality, and computes the absolute difference between the compressed and original images. The difference is multiplied by a scale factor and returned as an ELA image.</p>\n",
    "\n",
    "<p style=\"font-size:20px; font-family:verdana; line-height: 1.7em\">The convert_to_ela_image() function takes an image path and a quality parameter, compresses the image using JPEG compression at the given quality, computes the absolute difference between the compressed and original images, and returns an ELA image. The ELA image is computed using the difference in pixel values between the original and compressed images, and is normalized to enhance the differences.</p>\n",
    "\n",
    "<p style=\"font-size:20px; font-family:verdana; line-height: 1.7em\">The random_sample() function takes a directory path and an optional file extension, and returns a random file path from that directory with the specified extension (if provided).</p>\n",
    "\n",
    "<p style=\"font-size:20px; font-family:verdana; line-height: 1.7em\">Finally, the code generates a set of ELA images using the compute_ela_cv() function for a randomly selected image from the test dataset of animals images. The ELA images are generated with decreasing quality levels, resulting in increasing levels of compression and thus increasing levels of error. The resulting images are plotted using matplotlib.</p>\n",
    "\n",
    "<p style=\"font-size:20px; font-family:verdana; line-height: 1.7em\">Overall, this code provides a way to visually analyze the effect of different levels of JPEG compression on animals images, and may be used to identify optimal quality levels for image compression in the context of a animals image classification task.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "editable": false,
    "execution": {
     "iopub.execute_input": "2023-04-08T09:32:07.496749Z",
     "iopub.status.busy": "2023-04-08T09:32:07.490663Z",
     "iopub.status.idle": "2023-04-08T09:32:07.519076Z",
     "shell.execute_reply": "2023-04-08T09:32:07.517695Z",
     "shell.execute_reply.started": "2023-04-08T09:32:07.496708Z"
    },
    "papermill": {
     "duration": 0.031029,
     "end_time": "2022-10-10T07:48:10.430201",
     "exception": false,
     "start_time": "2022-10-10T07:48:10.399172",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def compute_ela_cv(path, quality):\n",
    "    temp_filename = 'temp_file_name.jpeg'\n",
    "    SCALE = 15\n",
    "    orig_img = cv2.imread(path)\n",
    "    orig_img = cv2.cvtColor(orig_img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    cv2.imwrite(temp_filename, orig_img, [cv2.IMWRITE_JPEG_QUALITY, quality])\n",
    "\n",
    "    # read compressed image\n",
    "    compressed_img = cv2.imread(temp_filename)\n",
    "\n",
    "    # get absolute difference between img1 and img2 and multiply by scale\n",
    "    diff = SCALE * cv2.absdiff(orig_img, compressed_img)\n",
    "    return diff\n",
    "\n",
    "\n",
    "def convert_to_ela_image(path, quality):\n",
    "    temp_filename = 'temp_file_name.jpeg'\n",
    "    ela_filename = 'temp_ela.png'\n",
    "    image = Image.open(path).convert('RGB')\n",
    "    image.save(temp_filename, 'JPEG', quality = quality)\n",
    "    temp_image = Image.open(temp_filename)\n",
    "\n",
    "    ela_image = ImageChops.difference(image, temp_image)\n",
    "\n",
    "    extrema = ela_image.getextrema()\n",
    "    max_diff = max([ex[1] for ex in extrema])\n",
    "    if max_diff == 0:\n",
    "        max_diff = 1\n",
    "\n",
    "    scale = 255.0 / max_diff\n",
    "    ela_image = ImageEnhance.Brightness(ela_image).enhance(scale)\n",
    "    \n",
    "    return ela_image\n",
    "\n",
    "\n",
    "def random_sample(path, extension=None):\n",
    "    if extension:\n",
    "        items = Path(path).glob(f'*.{extension}')\n",
    "    else:\n",
    "        items = Path(path).glob(f'*')\n",
    "        \n",
    "    items = list(items)\n",
    "        \n",
    "    p = random.choice(items)\n",
    "    return p.as_posix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2023-04-08T09:32:07.521176Z",
     "iopub.status.busy": "2023-04-08T09:32:07.520804Z",
     "iopub.status.idle": "2023-04-08T09:32:09.831648Z",
     "shell.execute_reply": "2023-04-08T09:32:09.830724Z",
     "shell.execute_reply.started": "2023-04-08T09:32:07.521143Z"
    },
    "papermill": {
     "duration": 1.189411,
     "end_time": "2022-10-10T07:48:11.637574",
     "exception": false,
     "start_time": "2022-10-10T07:48:10.448163",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# View random sample from the dataset\n",
    "p = random_sample(dataset+'/cane')\n",
    "orig = cv2.imread(p)\n",
    "orig = cv2.cvtColor(orig, cv2.COLOR_BGR2RGB) / 255.0\n",
    "init_val = 100\n",
    "columns = 3\n",
    "rows = 3\n",
    "\n",
    "fig=plt.figure(figsize=(15, 10))\n",
    "for i in range(1, columns*rows +1):\n",
    "    quality=init_val - (i-1) * 8\n",
    "    img = compute_ela_cv(path=p, quality=quality)\n",
    "    if i == 1:\n",
    "        img = orig.copy()\n",
    "    ax = fig.add_subplot(rows, columns, i) \n",
    "    ax.title.set_text(f'q: {quality}')\n",
    "    plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "id": "YwC4EWei1s-V",
    "papermill": {
     "duration": 0.032142,
     "end_time": "2022-10-10T07:48:11.709531",
     "exception": false,
     "start_time": "2022-10-10T07:48:11.677389",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# üìùData Preprocessing\n",
    "<div style=\"background-color:#f2f2f2; padding: 20px;\">\n",
    "<p style=\"font-size:20px; font-family:verdana; line-height: 1.7em\">The data will be split into three different categories: Training, Validation and Testing. The training data will be used to train the deep learning CNN model and its parameters will be fine tuned with the validation data. Finally, the performance of the data will be evaluated using the test data(data the model has not previously seen).</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2023-04-08T09:32:09.833541Z",
     "iopub.status.busy": "2023-04-08T09:32:09.832935Z",
     "iopub.status.idle": "2023-04-08T09:32:09.845883Z",
     "shell.execute_reply": "2023-04-08T09:32:09.844617Z",
     "shell.execute_reply.started": "2023-04-08T09:32:09.833501Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Separate in train and test data\n",
    "train_df, test_df = train_test_split(image_df, test_size=0.2, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2023-04-08T09:32:09.848108Z",
     "iopub.status.busy": "2023-04-08T09:32:09.847725Z",
     "iopub.status.idle": "2023-04-08T09:32:09.854909Z",
     "shell.execute_reply": "2023-04-08T09:32:09.853623Z",
     "shell.execute_reply.started": "2023-04-08T09:32:09.848074Z"
    },
    "id": "3puUVDwl2Mcz",
    "papermill": {
     "duration": 0.042276,
     "end_time": "2022-10-10T07:48:11.867829",
     "exception": false,
     "start_time": "2022-10-10T07:48:11.825553",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_generator = ImageDataGenerator(\n",
    "    preprocessing_function=tf.keras.applications.efficientnet.preprocess_input,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "test_generator = ImageDataGenerator(\n",
    "    preprocessing_function=tf.keras.applications.efficientnet.preprocess_input,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2023-04-08T09:32:09.860512Z",
     "iopub.status.busy": "2023-04-08T09:32:09.859988Z",
     "iopub.status.idle": "2023-04-08T09:32:25.013885Z",
     "shell.execute_reply": "2023-04-08T09:32:25.012697Z",
     "shell.execute_reply.started": "2023-04-08T09:32:09.860475Z"
    },
    "id": "CsftNShQ2PaK",
    "outputId": "ee3c99b5-3932-4187-f600-1e86cf334026",
    "papermill": {
     "duration": 0.950749,
     "end_time": "2022-10-10T07:48:12.851195",
     "exception": false,
     "start_time": "2022-10-10T07:48:11.900446",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Split the data into three categories.\n",
    "train_images = train_generator.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col='Filepath',\n",
    "    y_col='Label',\n",
    "    target_size=TARGET_SIZE,\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "val_images = train_generator.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col='Filepath',\n",
    "    y_col='Label',\n",
    "    target_size=TARGET_SIZE,\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "test_images = test_generator.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    x_col='Filepath',\n",
    "    y_col='Label',\n",
    "    target_size=TARGET_SIZE,\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "editable": false,
    "execution": {
     "iopub.execute_input": "2023-04-08T09:32:25.0159Z",
     "iopub.status.busy": "2023-04-08T09:32:25.015213Z",
     "iopub.status.idle": "2023-04-08T09:32:25.43319Z",
     "shell.execute_reply": "2023-04-08T09:32:25.432166Z",
     "shell.execute_reply.started": "2023-04-08T09:32:25.015862Z"
    },
    "id": "sLbR4WtD2RPg",
    "papermill": {
     "duration": 2.906278,
     "end_time": "2022-10-10T07:48:15.791045",
     "exception": false,
     "start_time": "2022-10-10T07:48:12.884767",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Data Augmentation Step\n",
    "augment = tf.keras.Sequential([\n",
    "  layers.Resizing(224,224),\n",
    "  layers.Rescaling(1./255),\n",
    "  layers.RandomFlip(\"horizontal\"),\n",
    "  layers.RandomRotation(0.1),\n",
    "  layers.RandomZoom(0.1),\n",
    "  layers.RandomContrast(0.1),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "id": "xSEhK2w02Uk-",
    "papermill": {
     "duration": 0.032912,
     "end_time": "2022-10-10T07:48:15.858067",
     "exception": false,
     "start_time": "2022-10-10T07:48:15.825155",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ü§πTraining the model\n",
    "<div style=\"background-color:#f2f2f2; padding: 20px;\">\n",
    "  <p style=\"font-size:20px; font-family:verdana; line-height: 1.7em\">The model images will be subjected to a pre-trained CNN model called EfficientNetB7. Three callbacks will be utilized to monitor the training. These are: Model Checkpoint, Early Stopping, Tensorboard callback. The summary of the model hyperparameter is shown as follows:</p>\n",
    "\n",
    "  <p style=\"font-size:20px\">\n",
    "    <strong>Batch size</strong>: 32<br>\n",
    "    <strong>Epochs</strong>: 100<br>\n",
    "    <strong>Input Shape</strong>: (224, 224, 3)<br>\n",
    "    <strong>Output layer</strong>: 10\n",
    "  </p>\n",
    "</div>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2023-04-08T09:32:25.43486Z",
     "iopub.status.busy": "2023-04-08T09:32:25.434516Z",
     "iopub.status.idle": "2023-04-08T09:32:34.176169Z",
     "shell.execute_reply": "2023-04-08T09:32:34.175151Z",
     "shell.execute_reply.started": "2023-04-08T09:32:25.434824Z"
    },
    "id": "z4VI_UxV2Wp2",
    "papermill": {
     "duration": 2.633611,
     "end_time": "2022-10-10T07:48:18.524309",
     "exception": false,
     "start_time": "2022-10-10T07:48:15.890698",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load the pretained model\n",
    "pretrained_model = tf.keras.applications.efficientnet.EfficientNetB7(\n",
    "    input_shape=(224, 224, 3),\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    pooling='max'\n",
    ")\n",
    "\n",
    "pretrained_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2023-04-08T09:32:34.179076Z",
     "iopub.status.busy": "2023-04-08T09:32:34.178327Z",
     "iopub.status.idle": "2023-04-08T09:32:34.18587Z",
     "shell.execute_reply": "2023-04-08T09:32:34.184898Z",
     "shell.execute_reply.started": "2023-04-08T09:32:34.179035Z"
    },
    "id": "1xn6j_La2Y2u",
    "papermill": {
     "duration": 0.043774,
     "end_time": "2022-10-10T07:48:18.601867",
     "exception": false,
     "start_time": "2022-10-10T07:48:18.558093",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create checkpoint callback\n",
    "checkpoint_path = \"animals_classification_model_checkpoint.weights.h5\"\n",
    "checkpoint_callback = ModelCheckpoint(checkpoint_path,\n",
    "                                      save_weights_only=True,\n",
    "                                      monitor=\"val_accuracy\",\n",
    "                                      save_best_only=True)\n",
    "\n",
    "# Setup EarlyStopping callback to stop training if model's val_loss doesn't improve for 3 epochs\n",
    "early_stopping = EarlyStopping(monitor = \"val_loss\", # watch the val loss metric\n",
    "                               patience = 5,\n",
    "                               restore_best_weights = True) # if val loss decreases for 3 epochs in a row, stop training\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "id": "alynENS02jm4",
    "papermill": {
     "duration": 0.032303,
     "end_time": "2022-10-10T07:48:18.741748",
     "exception": false,
     "start_time": "2022-10-10T07:48:18.709445",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# üöÑTraining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "editable": false,
    "execution": {
     "iopub.execute_input": "2023-04-08T09:33:52.886494Z",
     "iopub.status.busy": "2023-04-08T09:33:52.885934Z",
     "iopub.status.idle": "2023-04-08T09:37:01.159535Z",
     "shell.execute_reply": "2023-04-08T09:37:01.158477Z",
     "shell.execute_reply.started": "2023-04-08T09:33:52.886453Z"
    },
    "id": "AkcAsl5H2tYl",
    "outputId": "173d8e87-7f30-401e-fe3b-077c21025b59",
    "papermill": {
     "duration": 491.647837,
     "end_time": "2022-10-10T07:56:30.421938",
     "exception": false,
     "start_time": "2022-10-10T07:48:18.774101",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "inputs = pretrained_model.input\n",
    "x = augment(inputs)\n",
    "\n",
    "x = Dense(128, activation='relu')(pretrained_model.output)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.45)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.45)(x)\n",
    "\n",
    "\n",
    "outputs = Dense(10, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(0.00001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_images,\n",
    "    steps_per_epoch=len(train_images),\n",
    "    validation_data=val_images,\n",
    "    validation_steps=len(val_images),\n",
    "    epochs=100,\n",
    "    callbacks=[\n",
    "        early_stopping,\n",
    "        create_tensorboard_callback(\"training_logs\", \n",
    "                                    \"animals_classification\"),\n",
    "        checkpoint_callback,\n",
    "        reduce_lr\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "id": "_BWrofxS2vO0",
    "papermill": {
     "duration": 0.321214,
     "end_time": "2022-10-10T07:56:31.018691",
     "exception": false,
     "start_time": "2022-10-10T07:56:30.697477",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ‚úîÔ∏èModel Evaluation\n",
    "<div style=\"background-color:#f2f2f2; padding: 20px;\">\n",
    "<p style=\"font-size:20px; font-family:verdana; line-height: 1.7em\">The test dataset will be used to evaluate the performance of the model.One of the metrics that will be tested would be accuracy which measures the fraction of predictions the model got right. Other metrics are as follows:   </p>\n",
    "\n",
    "<h3>Precision(P):</h3> \n",
    "<p style=\"font-size:20px; font-family:verdana; line-height: 1.7em\">The fraction of true positives (TP, correct predictions) from the total amount of relevant results, i.e., the sum of TP and false positives (FP). For multi-class classification problems, P is averaged among the classes. The following is the formula for precision.</p>\n",
    "\n",
    "<h4>\n",
    "  <center>\n",
    "    <span style=\"font-size: 1.5em\">\n",
    "      $P = \\frac{TP}{TP+FP}$\n",
    "    </span>\n",
    "  </center>\n",
    "</h4>\n",
    "\n",
    "\n",
    "<h3>Recall(R): </h3> \n",
    "<p style=\"font-size:20px; font-family:verdana; line-height: 1.7em\">The fraction of TP from the total amount of TP and false negatives (FN). For multi-class classification problems, R gets averaged among all the classes. The following is the formula for recall.</p>\n",
    "\n",
    "<h4>\n",
    "  <center>\n",
    "    <span style=\"font-size: 1.5em\">\n",
    "      $R = \\frac{TP}{TP+FN}$\n",
    "    </span>\n",
    "  </center>\n",
    "</h4>\n",
    "\n",
    "\n",
    "<h3>F1 score(F1): </h3>\n",
    "\n",
    "<p style=\"font-size:20px; font-family:verdana; line-height: 1.7em\">The harmonic mean of precision and recall. For multi-class classification problems, F1 gets averaged among all the classes. The following is the formula for F1 score.</p>\n",
    "\n",
    "<h4>\n",
    "  <center>\n",
    "    <span style=\"font-size: 1.5em\">\n",
    "      $F1 = 2 \\times \\frac{TP \\times FP}{TP + FP}$\n",
    "    </span>\n",
    "  </center>\n",
    "</h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2023-04-08T09:37:54.389446Z",
     "iopub.status.busy": "2023-04-08T09:37:54.388774Z",
     "iopub.status.idle": "2023-04-08T09:38:38.264266Z",
     "shell.execute_reply": "2023-04-08T09:38:38.263258Z",
     "shell.execute_reply.started": "2023-04-08T09:37:54.389405Z"
    },
    "id": "CS-g90hJ340B",
    "outputId": "8b35403d-9dc0-4a65-b08e-ce223aef2bdb",
    "papermill": {
     "duration": 2.39154,
     "end_time": "2022-10-10T07:56:33.685702",
     "exception": false,
     "start_time": "2022-10-10T07:56:31.294162",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "results = model.evaluate(test_images, verbose=0)\n",
    "\n",
    "print(\"    Test Loss: {:.5f}\".format(results[0]))\n",
    "print(\"Test Accuracy: {:.2f}%\".format(results[1] * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "id": "t5oGHvsG368q",
    "papermill": {
     "duration": 0.274766,
     "end_time": "2022-10-10T07:56:34.232747",
     "exception": false,
     "start_time": "2022-10-10T07:56:33.957981",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# üìâVisualizing loss curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2023-04-08T09:38:38.267263Z",
     "iopub.status.busy": "2023-04-08T09:38:38.266838Z",
     "iopub.status.idle": "2023-04-08T09:38:38.68528Z",
     "shell.execute_reply": "2023-04-08T09:38:38.684259Z",
     "shell.execute_reply.started": "2023-04-08T09:38:38.267204Z"
    },
    "id": "01SS6RVx38o7",
    "outputId": "f982ac64-9de4-4306-c917-1b7a1d0f6e06",
    "papermill": {
     "duration": 0.734988,
     "end_time": "2022-10-10T07:56:35.241277",
     "exception": false,
     "start_time": "2022-10-10T07:56:34.506289",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "accuracy = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(accuracy))\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "ax1.plot(epochs, accuracy, 'b', label='Training accuracy')\n",
    "ax1.plot(epochs, val_accuracy, 'r', label='Validation accuracy')\n",
    "ax1.set_title('Training and validation accuracy')\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax1.set_ylabel('Accuracy')\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot(epochs, loss, 'b', label='Training loss')\n",
    "ax2.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "ax2.set_title('Training and validation loss')\n",
    "ax2.set_xlabel('Epochs')\n",
    "ax2.set_ylabel('Loss')\n",
    "ax2.legend()\n",
    "\n",
    "fig.suptitle('Training and validation metrics', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "id": "0BL7xgPz4Fv-",
    "papermill": {
     "duration": 0.27217,
     "end_time": "2022-10-10T07:56:35.786961",
     "exception": false,
     "start_time": "2022-10-10T07:56:35.514791",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# üîÆMaking predictions on the Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2023-04-08T09:38:38.687619Z",
     "iopub.status.busy": "2023-04-08T09:38:38.686705Z",
     "iopub.status.idle": "2023-04-08T09:39:20.825215Z",
     "shell.execute_reply": "2023-04-08T09:39:20.823925Z",
     "shell.execute_reply.started": "2023-04-08T09:38:38.687577Z"
    },
    "id": "KxAegJBB4HlW",
    "outputId": "c836256c-be8e-4346-b6c2-d4c39d030db4",
    "papermill": {
     "duration": 2.219323,
     "end_time": "2022-10-10T07:56:38.279045",
     "exception": false,
     "start_time": "2022-10-10T07:56:36.059722",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Predict the label of the test_images\n",
    "pred = model.predict(test_images)\n",
    "pred = np.argmax(pred,axis=1)\n",
    "\n",
    "# Map the label\n",
    "labels = (train_images.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "pred = [labels[k] for k in pred]\n",
    "\n",
    "# Display the result\n",
    "print(f'The first 5 predictions: {pred[:5]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2023-04-08T09:39:20.828903Z",
     "iopub.status.busy": "2023-04-08T09:39:20.82798Z",
     "iopub.status.idle": "2023-04-08T09:39:22.321026Z",
     "shell.execute_reply": "2023-04-08T09:39:22.319594Z",
     "shell.execute_reply.started": "2023-04-08T09:39:20.828859Z"
    },
    "id": "pWO4e4wb4Iln",
    "outputId": "a58f3382-f991-43ac-e54f-6bd9a36dd25f",
    "papermill": {
     "duration": 1.448719,
     "end_time": "2022-10-10T07:56:40.005973",
     "exception": false,
     "start_time": "2022-10-10T07:56:38.557254",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "  # Display 25 random pictures from the dataset with their labels\n",
    "random_index = np.random.randint(0, len(test_df) - 1, 15)\n",
    "fig, axes = plt.subplots(nrows=3, ncols=5, figsize=(25, 15),\n",
    "                        subplot_kw={'xticks': [], 'yticks': []})\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(plt.imread(test_df.Filepath.iloc[random_index[i]]))\n",
    "    if test_df.Label.iloc[random_index[i]] == pred[random_index[i]]:\n",
    "        color = \"green\"\n",
    "    else:\n",
    "        color = \"red\"\n",
    "    ax.set_title(f\"True: {test_df.Label.iloc[random_index[i]]}\\nPredicted: {pred[random_index[i]]}\", color=color)\n",
    "plt.show()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "id": "jLYd5vYJ4KTu",
    "papermill": {
     "duration": 0.289751,
     "end_time": "2022-10-10T07:56:40.58392",
     "exception": false,
     "start_time": "2022-10-10T07:56:40.294169",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# üìäPlotting the Classification Reports and Confusion Matrix\n",
    "\n",
    "<div style=\"background-color:#f2f2f2; padding: 20px;\">\n",
    "<p style=\"font-size:20px; font-family:verdana; line-height: 1.7em\"><b>Confusion matrix</b> and <b>classification report</b> are two important tools used for evaluating the performance of an image classification model.</p>\n",
    "\n",
    "<p style=\"font-size:20px; font-family:verdana; line-height: 1.7em\">A <b>confusion matrix</b> is a table that summarizes the number of correct and incorrect predictions made by a classification model on a set of test data. It is usually represented as a square matrix with rows and columns representing the predicted and true class labels, respectively. The entries of the matrix indicate the number of test samples that belong to a certain class, and how many of those were classified correctly or incorrectly by the model. A confusion matrix can provide a detailed breakdown of the performance of the model, including measures such as accuracy, precision, recall, and F1-score for each class. It can be used to identify specific areas where the model is making errors, and to diagnose problems with the model's predictions.</p>\n",
    "\n",
    "<p style=\"font-size:20px; font-family:verdana; line-height: 1.7em\">A <b>classification report</b> is a summary of the key performance metrics for a classification model, including precision, recall, and F1-score, as well as the overall accuracy of the model. It provides a concise overview of the model's performance, typically broken down by class, and can be used to quickly assess the strengths and weaknesses of the model. The report is often presented as a table, with each row representing a class and columns showing various performance metrics. The report may also include other metrics such as support (the number of test samples belonging to a particular class), and the macro- and micro-averages of the performance metrics across all classes.</p>\n",
    "\n",
    "<p style=\"font-size:20px; font-family:verdana; line-height: 1.7em\">In image classification, both confusion matrix and classification report are important tools for evaluating the performance of the model, identifying areas for improvement, and making decisions about how to adjust the model's architecture or training parameters.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2023-04-08T09:39:22.323481Z",
     "iopub.status.busy": "2023-04-08T09:39:22.322854Z",
     "iopub.status.idle": "2023-04-08T09:39:22.422594Z",
     "shell.execute_reply": "2023-04-08T09:39:22.421314Z",
     "shell.execute_reply.started": "2023-04-08T09:39:22.323443Z"
    },
    "id": "6ySAZoU74MlB",
    "outputId": "b4c6bf97-d4b1-4def-d1a8-bb79c9685504",
    "papermill": {
     "duration": 0.385517,
     "end_time": "2022-10-10T07:56:41.407629",
     "exception": false,
     "start_time": "2022-10-10T07:56:41.022112",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "y_test = list(test_df.Label)\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2023-04-08T09:39:22.424785Z",
     "iopub.status.busy": "2023-04-08T09:39:22.424308Z",
     "iopub.status.idle": "2023-04-08T09:39:22.503253Z",
     "shell.execute_reply": "2023-04-08T09:39:22.502097Z",
     "shell.execute_reply.started": "2023-04-08T09:39:22.424735Z"
    },
    "id": "bYWvkbXI4Ns2",
    "outputId": "7e04d8a2-3263-4a31-d469-70d8140cb167",
    "papermill": {
     "duration": 0.363746,
     "end_time": "2022-10-10T07:56:42.071383",
     "exception": false,
     "start_time": "2022-10-10T07:56:41.707637",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "report = classification_report(y_test, pred, output_dict=True)\n",
    "df = pd.DataFrame(report).transpose()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "editable": false,
    "execution": {
     "iopub.execute_input": "2023-04-08T09:39:22.505904Z",
     "iopub.status.busy": "2023-04-08T09:39:22.504996Z",
     "iopub.status.idle": "2023-04-08T09:39:22.519543Z",
     "shell.execute_reply": "2023-04-08T09:39:22.518546Z",
     "shell.execute_reply.started": "2023-04-08T09:39:22.505863Z"
    },
    "id": "QS8khAfS4Oy3",
    "papermill": {
     "duration": 0.301023,
     "end_time": "2022-10-10T07:56:42.66035",
     "exception": false,
     "start_time": "2022-10-10T07:56:42.359327",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def make_confusion_matrix(y_true, y_pred, classes=None, figsize=(15, 7), text_size=10, norm=False, savefig=False): \n",
    "    \"\"\"Makes a labelled confusion matrix comparing predictions and ground truth labels.\n",
    "\n",
    "    If classes is passed, confusion matrix will be labelled, if not, integer class values\n",
    "  will be used.\n",
    "\n",
    "  Args:\n",
    "    y_true: Array of truth labels (must be same shape as y_pred).\n",
    "    y_pred: Array of predicted labels (must be same shape as y_true).\n",
    "    classes: Array of class labels (e.g. string form). If `None`, integer labels are used.\n",
    "    figsize: Size of output figure (default=(10, 10)).\n",
    "    text_size: Size of output figure text (default=15).\n",
    "    norm: normalize values or not (default=False).\n",
    "    savefig: save confusion matrix to file (default=False).\n",
    "  \n",
    "  Returns:\n",
    "    A labelled confusion matrix plot comparing y_true and y_pred.\n",
    "\n",
    "  Example usage:\n",
    "    make_confusion_matrix(y_true=test_labels, # ground truth test labels\n",
    "                          y_pred=y_preds, # predicted labels\n",
    "                          classes=class_names, # array of class label names\n",
    "                          figsize=(15, 15),\n",
    "                          text_size=10)\n",
    "    \"\"\"  \n",
    "  # Create the confustion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    cm_norm = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis] # normalize it\n",
    "    n_classes = cm.shape[0] # find the number of classes we're dealing with\n",
    "\n",
    "    # Plot the figure and make it pretty\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    cax = ax.matshow(cm, cmap=plt.cm.Blues) # colors will represent how 'correct' a class is, darker == better\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    # Are there a list of classes?\n",
    "    if classes:\n",
    "        labels = classes\n",
    "    else:\n",
    "        labels = np.arange(cm.shape[0])\n",
    "  \n",
    "    # Label the axes\n",
    "    ax.set(title=\"Confusion Matrix\",\n",
    "         xlabel=\"Predicted label\",\n",
    "         ylabel=\"True label\",\n",
    "         xticks=np.arange(n_classes), # create enough axis slots for each class\n",
    "         yticks=np.arange(n_classes), \n",
    "         xticklabels=labels, # axes will labeled with class names (if they exist) or ints\n",
    "         yticklabels=labels)\n",
    "  \n",
    "    # Make x-axis labels appear on bottom\n",
    "    ax.xaxis.set_label_position(\"bottom\")\n",
    "    ax.xaxis.tick_bottom()\n",
    "    ### Added: Rotate xticks for readability & increase font size (required due to such a large confusion matrix)\n",
    "    plt.xticks(rotation=90, fontsize=text_size)\n",
    "    plt.yticks(fontsize=text_size)\n",
    "\n",
    "    # Set the threshold for different colors\n",
    "    threshold = (cm.max() + cm.min()) / 2.\n",
    "\n",
    "    # Plot the text on each cell\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if norm:\n",
    "            plt.text(j, i, f\"{cm[i, j]} ({cm_norm[i, j]*100:.1f}%)\",\n",
    "                horizontalalignment=\"center\",\n",
    "                color=\"white\" if cm[i, j] > threshold else \"black\",\n",
    "                size=text_size)\n",
    "        else:\n",
    "            plt.text(j, i, f\"{cm[i, j]}\",\n",
    "              horizontalalignment=\"center\",\n",
    "              color=\"white\" if cm[i, j] > threshold else \"black\",\n",
    "              size=text_size)\n",
    "\n",
    "  # Save the figure to the current working directory\n",
    "    if savefig:\n",
    "        fig.savefig(\"confusion_matrix.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2023-04-08T09:39:22.521849Z",
     "iopub.status.busy": "2023-04-08T09:39:22.521435Z",
     "iopub.status.idle": "2023-04-08T09:39:23.272189Z",
     "shell.execute_reply": "2023-04-08T09:39:23.271181Z",
     "shell.execute_reply.started": "2023-04-08T09:39:22.521811Z"
    },
    "id": "vMsUQM6n4Pyx",
    "outputId": "3eb72904-123b-4e7b-d5b6-e3e339fab375",
    "papermill": {
     "duration": 0.692437,
     "end_time": "2022-10-10T07:56:43.641789",
     "exception": false,
     "start_time": "2022-10-10T07:56:42.949352",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "make_confusion_matrix(y_test, pred, list(labels.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "papermill": {
     "duration": 0.529168,
     "end_time": "2022-10-10T07:56:44.621387",
     "exception": false,
     "start_time": "2022-10-10T07:56:44.092219",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ‚òÄÔ∏èGrad-Cam Visualization\n",
    "\n",
    "<div style=\"background-color:#f2f2f2; padding: 20px;\">\n",
    "<p style=\"font-size:20px; font-family:verdana; line-height: 1.7em\"><b>Grad-CAM (Gradient-weighted Class Activation Mapping)</b> is a technique used to visualize the regions of an input image that were most relevant for a neural network's prediction. It allows you to see which regions of the image the model focused on while making its prediction. Grad-CAM is a modification of the CAM technique that extends the latter to any model that uses a convolutional neural network (CNN) as its underlying architecture.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "editable": false,
    "execution": {
     "iopub.execute_input": "2023-04-08T09:39:23.274887Z",
     "iopub.status.busy": "2023-04-08T09:39:23.274153Z",
     "iopub.status.idle": "2023-04-08T09:39:23.29027Z",
     "shell.execute_reply": "2023-04-08T09:39:23.289081Z",
     "shell.execute_reply.started": "2023-04-08T09:39:23.274847Z"
    },
    "papermill": {
     "duration": 0.319471,
     "end_time": "2022-10-10T07:56:45.261889",
     "exception": false,
     "start_time": "2022-10-10T07:56:44.942418",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_img_array(img_path, size):\n",
    "    img = tf.keras.preprocessing.image.load_img(img_path, target_size=size)\n",
    "    array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    # We add a dimension to transform our array into a \"batch\"\n",
    "    # of size \"size\"\n",
    "    array = np.expand_dims(array, axis=0)\n",
    "    return array\n",
    "\n",
    "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
    "    # First, we create a model that maps the input image to the activations\n",
    "    # of the last conv layer as well as the output predictions\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
    "    )\n",
    "\n",
    "    # Then, we compute the gradient of the top predicted class for our input image\n",
    "    # with respect to the activations of the last conv layer\n",
    "    with tf.GradientTape() as tape:\n",
    "        last_conv_layer_output, preds = grad_model(img_array)\n",
    "        if pred_index is None:\n",
    "            pred_index = tf.argmax(preds[0])\n",
    "        class_channel = preds[:, pred_index]\n",
    "    # This is the gradient of the output neuron (top predicted or chosen)\n",
    "    # with regard to the output feature map of the last conv layer\n",
    "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
    "\n",
    "    # This is a vector where each entry is the mean intensity of the gradient\n",
    "    # over a specific feature map channel\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "    # We multiply each channel in the feature map array\n",
    "    # by \"how important this channel is\" with regard to the top predicted class\n",
    "    # then sum all the channels to obtain the heatmap class activation\n",
    "    last_conv_layer_output = last_conv_layer_output[0]\n",
    "    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
    "    heatmap = tf.squeeze(heatmap)\n",
    "\n",
    "    # For visualization purpose, we will also normalize the heatmap between 0 & 1\n",
    "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
    "    return heatmap.numpy()\n",
    "def save_and_display_gradcam(img_path, heatmap, cam_path=\"cam.jpg\", alpha=0.4):\n",
    "    # Load the original image\n",
    "    img = tf.keras.preprocessing.image.load_img(img_path)\n",
    "    img = tf.keras.preprocessing.image.img_to_array(img)\n",
    "\n",
    "    # Rescale heatmap to a range 0-255\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "\n",
    "    # Use jet colormap to colorize heatmap\n",
    "    jet = cm.get_cmap(\"jet\")\n",
    "\n",
    "    # Use RGB values of the colormap\n",
    "    jet_colors = jet(np.arange(256))[:, :3]\n",
    "    jet_heatmap = jet_colors[heatmap]\n",
    "\n",
    "    # Create an image with RGB colorized heatmap\n",
    "    jet_heatmap = tf.keras.preprocessing.image.array_to_img(jet_heatmap)\n",
    "    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n",
    "    jet_heatmap = tf.keras.preprocessing.image.img_to_array(jet_heatmap)\n",
    "\n",
    "    # Superimpose the heatmap on original image\n",
    "    superimposed_img = jet_heatmap * alpha + img\n",
    "    superimposed_img = tf.keras.preprocessing.image.array_to_img(superimposed_img)\n",
    "    # Save the superimposed image\n",
    "    superimposed_img.save(cam_path)\n",
    "\n",
    "    # Display Grad CAM\n",
    "#     display(Image(cam_path))\n",
    "    \n",
    "    return cam_path\n",
    "    \n",
    "\n",
    "preprocess_input = tf.keras.applications.efficientnet.preprocess_input\n",
    "decode_predictions = tf.keras.applications.efficientnet.decode_predictions\n",
    "\n",
    "last_conv_layer_name = \"top_conv\"\n",
    "img_size = (224,224, 3)\n",
    "\n",
    "# Remove last layer's softmax\n",
    "model.layers[-1].activation = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2023-04-08T09:39:23.295082Z",
     "iopub.status.busy": "2023-04-08T09:39:23.294805Z",
     "iopub.status.idle": "2023-04-08T09:39:39.898649Z",
     "shell.execute_reply": "2023-04-08T09:39:39.897313Z",
     "shell.execute_reply.started": "2023-04-08T09:39:23.295055Z"
    },
    "papermill": {
     "duration": 4.077374,
     "end_time": "2022-10-10T07:56:49.628428",
     "exception": false,
     "start_time": "2022-10-10T07:56:45.551054",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Display the part of the pictures used by the neural network to classify the pictures\n",
    "fig, axes = plt.subplots(nrows=3, ncols=5, figsize=(15, 10),\n",
    "                        subplot_kw={'xticks': [], 'yticks': []})\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    img_path = test_df.Filepath.iloc[random_index[i]]\n",
    "    img_array = preprocess_input(get_img_array(img_path, size=img_size))\n",
    "    heatmap = make_gradcam_heatmap(img_array, model, last_conv_layer_name)\n",
    "    cam_path = save_and_display_gradcam(img_path, heatmap)\n",
    "    ax.imshow(plt.imread(cam_path))\n",
    "    ax.set_title(f\"True: {test_df.Label.iloc[random_index[i]]}\\nPredicted: {pred[random_index[i]]}\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "id": "PGvdcGEI4RCb",
    "papermill": {
     "duration": 0.297024,
     "end_time": "2022-10-10T07:56:50.223184",
     "exception": false,
     "start_time": "2022-10-10T07:56:49.92616",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "***\n",
    "\n",
    "<div style=\"color:white;\n",
    "           display:fill;\n",
    "           border-radius:5px;\n",
    "           background-color:#5642C5;\n",
    "           font-size:110%;\n",
    "           font-family:Verdana;\n",
    "           letter-spacing:0.5px\">\n",
    "        <p style=\"padding: 10px;\n",
    "              color:white;\">\n",
    "            Thanks for viewing my work. If you like it, consider sharing it to others or give feedback to improve the notebook. Have a beautiful day my friend.\n",
    "        </p>\n",
    "    </div>\n",
    "\n",
    "<center><img src='https://media4.giphy.com/media/M9gbBd9nbDrOTu1Mqx/giphy.gif?cid=790b7611704aa2ca4e403287801480a6c753abf45f3e6242&rid=giphy.gif&ct=s' \n",
    "     height=30px width=160px /></center>"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 59760,
     "sourceId": 840806,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30458,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
